{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading True and Fake News files and merging them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = pd.read_csv('TrueNews.csv')\n",
    "df_fake = pd.read_csv('FakeNews.csv')\n",
    "df_true['label'] = 1\n",
    "df_fake['label'] = 0\n",
    "df = pd.concat([df_true, df_fake], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  RUBIO Sides With Democrats On Giving A Whoppin...   \n",
      "1   Ted Cruz Says Endorsing Trump Is A ‘Grave Mis...   \n",
      "2   ‘Responsible Gun Owner’ Road Rages, Threatens...   \n",
      "3  TEACHER’S UNION PROTEST Gets Ugly As Protester...   \n",
      "4  Etihad advises checks with U.S. missions after...   \n",
      "\n",
      "                                                text          subject  \\\n",
      "0  Democrats want to spend a whopping $2 billion ...         politics   \n",
      "1  Republican presidential candidate and Texas Se...             News   \n",
      "2  The National Rifle Association tells us that a...             News   \n",
      "3  In case you don t live in the Midwest, you mig...  Government News   \n",
      "4  DUBAI (Reuters) - Etihad Airways is advising s...     politicsNews   \n",
      "\n",
      "               date  label  \n",
      "0      May 16, 2016      0  \n",
      "1     March 1, 2016      0  \n",
      "2  February 2, 2016      0  \n",
      "3      Jan 20, 2016      0  \n",
      "4    March 7, 2017       1  \n",
      "                                                   title  \\\n",
      "44893   Paul Krugman: Obama Rolled Back RONALD REAGAN...   \n",
      "44894  Guatemala top court sides with U.N. graft unit...   \n",
      "44895  OOPS! NASA Makes Shocking Claim: Burning Fossi...   \n",
      "44896  Collapsing: Why the ‘Russia Hack’ Witch Hunt W...   \n",
      "44897  Jimmy Carter recovers from dehydration scare i...   \n",
      "\n",
      "                                                    text       subject  \\\n",
      "44893  Paul Krugman, by his own admission, has been d...          News   \n",
      "44894  GUATEMALA CITY (Reuters) - Guatemala s top cou...     worldnews   \n",
      "44895   UNDER MY PLAN   ELECTRICITY RATES WOULD NECES...     left-news   \n",
      "44896  21st Century Wire says Washington s Russian wi...       US_News   \n",
      "44897  WINNIPEG, Manitoba (Reuters) - Former U.S. Pre...  politicsNews   \n",
      "\n",
      "                   date  label  \n",
      "44893   January 4, 2016      0  \n",
      "44894  August 29, 2017       1  \n",
      "44895      Dec 23, 2015      0  \n",
      "44896    March 25, 2017      0  \n",
      "44897    July 14, 2017       1  \n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping and null rows and date column (as it's not a determinant whether a news a fake or real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5)\n",
      "(44898, 4)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "df = df.drop(['date'], axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small-casing all data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  rubio sides with democrats on giving a whoppin...   \n",
      "1   ted cruz says endorsing trump is a ‘grave mis...   \n",
      "2   ‘responsible gun owner’ road rages, threatens...   \n",
      "3  teacher’s union protest gets ugly as protester...   \n",
      "4  etihad advises checks with u.s. missions after...   \n",
      "\n",
      "                                                text          subject label  \n",
      "0  democrats want to spend a whopping $2 billion ...         politics     0  \n",
      "1  republican presidential candidate and texas se...             news     0  \n",
      "2  the national rifle association tells us that a...             news     0  \n",
      "3  in case you don t live in the midwest, you mig...  government news     0  \n",
      "4  dubai (reuters) - etihad airways is advising s...     politicsnews     1  \n"
     ]
    }
   ],
   "source": [
    "df = df.apply(lambda x: x.astype(str).str.lower())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing any extra spaces or links or special characters from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15056\\2168482054.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['title'] = df['title'].str.replace('[^\\w\\s]','')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15056\\2168482054.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['title'] = df['title'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15056\\2168482054.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['title'] = df['title'].str.replace('[^a-zA-Z]', ' ')\n"
     ]
    }
   ],
   "source": [
    "df['title'] = df['title'].str.replace('[^\\w\\s]','')\n",
    "df['title'] = df['title'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "df['title'] = df['title'].str.replace('[^a-zA-Z]', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15056\\2005404656.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'] = df['text'].str.replace('[^\\w\\s]','')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15056\\2005404656.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'] = df['text'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15056\\2005404656.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'] = df['text'].str.replace('[^a-zA-Z]', ' ')\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].str.replace('[^\\w\\s]','')\n",
    "df['text'] = df['text'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "df['text'] = df['text'].str.replace('[^a-zA-Z]', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  rubio sides with democrats on giving a whoppin...   \n",
      "1   ted cruz says endorsing trump is a grave mist...   \n",
      "2   responsible gun owner road rages threatens to...   \n",
      "3  teachers union protest gets ugly as protesters...   \n",
      "4  etihad advises checks with us missions after n...   \n",
      "\n",
      "                                                text          subject label  \n",
      "0  democrats want to spend a whopping   billion o...         politics     0  \n",
      "1  republican presidential candidate and texas se...             news     0  \n",
      "2  the national rifle association tells us that a...             news     0  \n",
      "3  in case you don t live in the midwest you migh...  government news     0  \n",
      "4  dubai reuters  etihad airways is advising some...     politicsnews     1  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  [rubio, sides, with, democrats, on, giving, a,...   \n",
      "1  [ted, cruz, says, endorsing, trump, is, a, gra...   \n",
      "2  [responsible, gun, owner, road, rages, threate...   \n",
      "3  [teachers, union, protest, gets, ugly, as, pro...   \n",
      "4  [etihad, advises, checks, with, us, missions, ...   \n",
      "\n",
      "                                                text          subject label  \n",
      "0  [democrats, want, to, spend, a, whopping, bill...         politics     0  \n",
      "1  [republican, presidential, candidate, and, tex...             news     0  \n",
      "2  [the, national, rifle, association, tells, us,...             news     0  \n",
      "3  [in, case, you, don, t, live, in, the, midwest...  government news     0  \n",
      "4  [dubai, reuters, etihad, airways, is, advising...     politicsnews     1  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df['title'] = df['title'].apply(lambda x: tokenizer.tokenize(x))\n",
    "df['text'] = df['text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  [rubio, side, with, democrat, on, giving, a, w...   \n",
      "1  [ted, cruz, say, endorsing, trump, is, a, grav...   \n",
      "2  [responsible, gun, owner, road, rage, threaten...   \n",
      "3  [teacher, union, protest, get, ugly, a, protes...   \n",
      "4  [etihad, advises, check, with, u, mission, aft...   \n",
      "\n",
      "                                                text          subject label  \n",
      "0  [democrat, want, to, spend, a, whopping, billi...         politics     0  \n",
      "1  [republican, presidential, candidate, and, tex...             news     0  \n",
      "2  [the, national, rifle, association, tell, u, t...             news     0  \n",
      "3  [in, case, you, don, t, live, in, the, midwest...  government news     0  \n",
      "4  [dubai, reuters, etihad, airway, is, advising,...     politicsnews     1  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['title'] = df['title'].apply(lambda x: [lemmatizer.lemmatize(y) for y in x])\n",
    "df['text'] = df['text'].apply(lambda x: [lemmatizer.lemmatize(y) for y in x])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  [rubio, side, democrat, giving, whopping, bill...   \n",
      "1  [ted, cruz, say, endorsing, trump, grave, mist...   \n",
      "2  [responsible, gun, owner, road, rage, threaten...   \n",
      "3  [teacher, union, protest, get, ugly, protester...   \n",
      "4  [etihad, advises, check, u, mission, new, trum...   \n",
      "\n",
      "                                                text          subject label  \n",
      "0  [democrat, want, spend, whopping, billion, zik...         politics     0  \n",
      "1  [republican, presidential, candidate, texas, s...             news     0  \n",
      "2  [national, rifle, association, tell, u, need, ...             news     0  \n",
      "3  [case, live, midwest, might, noticed, fight, c...  government news     0  \n",
      "4  [dubai, reuters, etihad, airway, advising, pas...     politicsnews     1  \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['title'] = df['title'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making another data frame with topic and text columns merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  rubio side democrat giving whopping billion zi...   \n",
      "1  ted cruz say endorsing trump grave mistake pro...   \n",
      "2  responsible gun owner road rage threatens shoo...   \n",
      "3  teacher union protest get ugly protester cop d...   \n",
      "4     etihad advises check u mission new trump order   \n",
      "\n",
      "                                                text          subject label  \\\n",
      "0  democrat want spend whopping billion zika viru...         politics     0   \n",
      "1  republican presidential candidate texas senato...             news     0   \n",
      "2  national rifle association tell u need ensure ...             news     0   \n",
      "3  case live midwest might noticed fight continue...  government news     0   \n",
      "4  dubai reuters etihad airway advising passenger...     politicsnews     1   \n",
      "\n",
      "                                          title_text  \n",
      "0  rubio side democrat giving whopping billion zi...  \n",
      "1  ted cruz say endorsing trump grave mistake pro...  \n",
      "2  responsible gun owner road rage threatens shoo...  \n",
      "3  teacher union protest get ugly protester cop d...  \n",
      "4  etihad advises check u mission new trump order...  \n"
     ]
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2['title'] = df2['title'].apply(lambda x: ' '.join(x))\n",
    "df2['text'] = df2['text'].apply(lambda x: ' '.join(x))\n",
    "df2['title_text'] = df2['title'] + ' ' + df2['text']\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to convert data to numerics using TFIDF and BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vector_Tfidf(df, col):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(max_features=2000)\n",
    "    vectorizer.fit(df[col])\n",
    "    return vectorizer.transform(df[col])\n",
    "\n",
    "def to_vector_bow(df, col):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vectorizer = CountVectorizer(max_features=2000)\n",
    "    vectorizer.fit(df[col])\n",
    "    return vectorizer.transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1996)\t0.4629419088058745\n",
      "  (0, 1634)\t0.4478063918308697\n",
      "  (0, 1537)\t0.409062487450288\n",
      "  (0, 747)\t0.44298578614975054\n",
      "  (0, 483)\t0.28177452318181667\n",
      "  (0, 185)\t0.37707932484096945\n",
      "  (1, 1893)\t0.22660073174650244\n",
      "  (1, 1841)\t0.1838503253174762\n",
      "  (1, 1769)\t0.5136887993459774\n",
      "  (1, 1558)\t0.2887695769171622\n",
      "  (1, 1391)\t0.5760965322164531\n",
      "  (1, 431)\t0.4854893414837819\n",
      "  (2, 1893)\t0.14335066558909626\n",
      "  (2, 1798)\t0.33777492844498125\n",
      "  (2, 1620)\t0.3743912245160185\n",
      "  (2, 1527)\t0.40172570833334936\n",
      "  (2, 1499)\t0.4051582246210042\n",
      "  (2, 1429)\t0.42945116825303636\n",
      "  (2, 1281)\t0.3582278769821827\n",
      "  (2, 782)\t0.2947840665970809\n",
      "  (3, 1893)\t0.15761364184178936\n",
      "  (3, 1864)\t0.3998080945150127\n",
      "  (3, 1858)\t0.47218031631323404\n",
      "  (3, 1765)\t0.4110980882863733\n",
      "  (3, 1404)\t0.34403542120714553\n",
      "  :\t:\n",
      "  (44893, 1242)\t0.24875230474013843\n",
      "  (44893, 440)\t0.3738612740911522\n",
      "  (44893, 142)\t0.3216312163792396\n",
      "  (44894, 1861)\t0.3394236290600913\n",
      "  (44894, 1814)\t0.34550222731762537\n",
      "  (44894, 1634)\t0.4758590376607832\n",
      "  (44894, 1369)\t0.27876925000630154\n",
      "  (44894, 769)\t0.47951707419826145\n",
      "  (44894, 665)\t0.37058758430148386\n",
      "  (44894, 412)\t0.30658426312458464\n",
      "  (44895, 1619)\t0.44020342037905164\n",
      "  (44895, 1258)\t0.49655541231227135\n",
      "  (44895, 1098)\t0.3438312536811531\n",
      "  (44895, 716)\t0.5329922569852585\n",
      "  (44895, 324)\t0.39667744349254425\n",
      "  (44896, 1962)\t0.43969479354489843\n",
      "  (44896, 1941)\t0.39411372756961827\n",
      "  (44896, 1543)\t0.2536242867966058\n",
      "  (44896, 863)\t0.4218978458979632\n",
      "  (44896, 785)\t0.36425135752232934\n",
      "  (44896, 582)\t0.322788567517734\n",
      "  (44896, 377)\t0.30149256876128094\n",
      "  (44896, 68)\t0.28504474604695895\n",
      "  (44897, 955)\t0.7474518371178778\n",
      "  (44897, 258)\t0.6643160025086778\n"
     ]
    }
   ],
   "source": [
    "title_vector_tfidf = to_vector_Tfidf(df2, 'title')\n",
    "text_vector_tfidf = to_vector_Tfidf(df2, 'text')\n",
    "title_text_vector_tfidf = to_vector_Tfidf(df2, 'title_text')\n",
    "title_vector_tfidf = title_vector_tfidf.toarray()\n",
    "text_vector_tfidf = text_vector_tfidf.toarray()\n",
    "title_text_vector_tfidf = title_text_vector_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vector_bow = to_vector_bow(df2, 'title')\n",
    "text_vector_bow = to_vector_bow(df2, 'text')\n",
    "title_text_vector_bow = to_vector_bow(df2, 'title_text')\n",
    "title_vector_bow = title_vector_bow.toarray()\n",
    "text_vector_bow = text_vector_bow.toarray()\n",
    "title_text_vector_bow = title_text_vector_bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of title_vector_tfidf, text_vector_tfidf, title_text_vector_tfidf:  (44898, 2000) (44898, 2000) (44898, 2000)\n",
      "Shapes of title_vector_bow, text_vector_bow, title_text_vector_bow:  (44898, 2000) (44898, 2000) (44898, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes of title_vector_tfidf, text_vector_tfidf, title_text_vector_tfidf: \", title_vector_tfidf.shape, text_vector_tfidf.shape, title_text_vector_tfidf.shape)\n",
    "print(\"Shapes of title_vector_bow, text_vector_bow, title_text_vector_bow: \", title_vector_bow.shape, text_vector_bow.shape, title_text_vector_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 1)\n",
      "(44898, 1)\n"
     ]
    }
   ],
   "source": [
    "subject = df['subject'].to_numpy()\n",
    "subject = subject.reshape(-1, 1)\n",
    "print(subject.shape)\n",
    "labels = df['label'].to_numpy()\n",
    "labels = labels.reshape(-1, 1)\n",
    "print(labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
